{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_baby_col(row):    \n",
    "    row = row.strip()\n",
    "    parent = row.split(')')\n",
    "    start = int(parent[0].split('(')[1].strip())\n",
    "    remaining = ')'.join(parent[1:])\n",
    "    remaining = remaining.strip(' ')\n",
    "    find_format = remaining.split('%')\n",
    "    dtypes_and_name = find_format[0].strip(' ')\n",
    "    types = [t for t in dtypes_and_name.split(' ') if t]\n",
    "    assert len(types) == 2, types\n",
    "    dtype = types[0].strip(' ')\n",
    "    name = types[1].strip(' ')\n",
    "    num_c = int(float(find_format[1].split(' ')[0].strip(' ')[:-1]))\n",
    "    end_of_str = 'f'.join(find_format[1].split('f')[1:])\n",
    "    end_of_str = end_of_str.strip(' \\r\\n')        \n",
    "    return {\n",
    "        'start': start,\n",
    "        'end': start + num_c,\n",
    "        'dtype': dtype,\n",
    "        'name': name,\n",
    "        'desc': end_of_str.strip('\"')\n",
    "    }\n",
    "\n",
    "def read_dct_file(dct):\n",
    "    \"\"\"\n",
    "    read dct file which defines field encoded in main text files\n",
    "    \"\"\"\n",
    "    with open(dct) as r:\n",
    "        chars_to_tab = r.readlines()\n",
    "        col_data = [decode_baby_col(c) for c in chars_to_tab if c.startswith('_column')]\n",
    "        \n",
    "    col_data_df = pd.DataFrame(col_data)\n",
    "    start = 1\n",
    "    columns = []\n",
    "    column_widths = []\n",
    "    for i, c in col_data_df.iterrows():\n",
    "        s = c['start']\n",
    "        e = c['end']\n",
    "        if s != start:\n",
    "            column_widths.append(s - start)\n",
    "            columns.append('blank{0}'.format(i))\n",
    "        columns.append(c['name'])\n",
    "        column_widths.append(e - s)\n",
    "        start = e\n",
    "    return col_data_df, columns, column_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_row_to_table(rowstr, column_df):\n",
    "    row = {}\n",
    "    for idx, data in column_df.iterrows():\n",
    "        info = rowstr[data['start'] - 1: data['end'] - 1]\n",
    "        # print(info, data['name'])\n",
    "        if data['dtype'] == 'int' or data['dtype'] == 'byte':\n",
    "            if not info.strip():\n",
    "                info = np.nan\n",
    "            else:\n",
    "                info = int(info)\n",
    "        elif data['dtype'] == 'double':\n",
    "            info = float(info)\n",
    "        elif data['dtype'] == 'str1':\n",
    "            info = str(info)\n",
    "        else:\n",
    "            info = str(info)\n",
    "        row[data['name']] = info\n",
    "    return row\n",
    "\n",
    "# def read_nat_data(file):\n",
    "#     with open(file) as r:\n",
    "#         for idx, l in enumerate(r):            \n",
    "#             data = read_row_to_table(l, column_reading)\n",
    "#             data['idx'] = idx            \n",
    "#             yield data\n",
    "\n",
    "\n",
    "# a = read_nat_data('Nat2018PublicUS.c20190509.r20190717.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a2 = pd.read_fwf(\n",
    "#     'Nat2018PublicUS.c20190509.r20190717.txt', \n",
    "#     sep='', header=None, chunksize=10000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file_as_df = []\n",
    "# for idx, d in enumerate(a):\n",
    "#     file_as_df.append(d)\n",
    "#     if idx % 100000 == 0:\n",
    "#         print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column_reading = column_reading.sort_values(by=['start'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_int(x):\n",
    "    if not isinstance(x, int) and not isinstance(x, float):\n",
    "        x = int(x) if not x.strip() else np.nan\n",
    "    return x\n",
    "\n",
    "def check_double(x):\n",
    "    if isinstance(x, int):\n",
    "        x = float(x)\n",
    "    elif not isinstance(x, float):\n",
    "        x = float(x) if not x.strip() else np.nan\n",
    "    return x\n",
    "\n",
    "def read_data(file, columns, col_widths, col_df, chunk=1000000):\n",
    "    desired_col = col_df['name'].values\n",
    "    a2 = pd.read_fwf(\n",
    "        file, sep='', \n",
    "        header=None, chunksize=chunk, widths=column_widths\n",
    "    )\n",
    "    groups = col_df.groupby(by=['dtype'])\n",
    "    \n",
    "    for df in a2:\n",
    "        df.columns = columns\n",
    "        \n",
    "        for d, grp in groups:\n",
    "            if d == 'int' or d == 'byte':\n",
    "                df[grp['name'].values] = df[grp['name'].values].applymap(check_int)\n",
    "            elif d == 'double':\n",
    "                df[grp['name'].values] = df[grp['name'].values].applymap(check_double)\n",
    "        \n",
    "        yield df[desired_col]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_df, columns, column_widths = read_dct_file('/mnt/nas/natality/2004/natl2004.dct')\n",
    "a = read_data('/mnt/nas/natality/2004/Nat2004us.dat', columns, column_widths, column_df, chunk=100)\n",
    "dfs = []\n",
    "for i, g in enumerate(a):    \n",
    "    dfs.append(g)\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged['educsmsa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = pd.concat(dfs)\n",
    "dfMerged['rectype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMerged.to_csv('Nat2018PublicUS.c20190509.r20190717.parsed.txt', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
