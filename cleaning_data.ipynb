{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_baby_col(row):    \n",
    "    row = row.strip()\n",
    "    parent = row.split(')')\n",
    "    start = int(parent[0].split('(')[1].strip())\n",
    "    remaining = ')'.join(parent[1:])\n",
    "    remaining = remaining.strip(' ')\n",
    "    find_format = remaining.split('%')\n",
    "    dtypes_and_name = find_format[0].strip(' ')\n",
    "    types = [t for t in dtypes_and_name.split(' ') if t]\n",
    "    assert len(types) == 2, types\n",
    "    dtype = types[0].strip(' ')\n",
    "    name = types[1].strip(' ')\n",
    "    num_c = int(float(find_format[1].split(' ')[0].strip(' ')[:-1]))\n",
    "    end_of_str = 'f'.join(find_format[1].split('f')[1:])\n",
    "    end_of_str = end_of_str.strip(' \\r\\n')        \n",
    "    return {\n",
    "        'start': start,\n",
    "        'end': start + num_c,\n",
    "        'dtype': dtype,\n",
    "        'name': name,\n",
    "        'desc': end_of_str.strip('\"')\n",
    "    }\n",
    "\n",
    "def read_dct_file(dct):\n",
    "    \"\"\"\n",
    "    read dct file which defines field encoded in main text files\n",
    "    \"\"\"\n",
    "    with open(dct) as r:\n",
    "        chars_to_tab = r.readlines()\n",
    "        col_data = [decode_baby_col(c) for c in chars_to_tab if c.startswith('_column')]\n",
    "        \n",
    "    col_data_df = pd.DataFrame(col_data)\n",
    "    start = 1\n",
    "    columns = []\n",
    "    column_widths = []\n",
    "    for i, c in col_data_df.iterrows():\n",
    "        s = c['start']\n",
    "        e = c['end']\n",
    "        if s != start:\n",
    "            column_widths.append(s - start)\n",
    "            columns.append('blank{0}'.format(i))\n",
    "        columns.append(c['name'])\n",
    "        column_widths.append(e - s)\n",
    "        start = e\n",
    "    return col_data_df, columns, column_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_row_to_table(rowstr, column_df):\n",
    "    row = {}\n",
    "    for idx, data in column_df.iterrows():\n",
    "        info = rowstr[data['start'] - 1: data['end'] - 1]\n",
    "        # print(info, data['name'])\n",
    "        if data['dtype'] == 'int' or data['dtype'] == 'byte':\n",
    "            if not info.strip():\n",
    "                info = np.nan\n",
    "            else:\n",
    "                info = int(info)\n",
    "        elif data['dtype'] == 'double':\n",
    "            info = float(info)\n",
    "        elif data['dtype'] == 'str1':\n",
    "            info = str(info)\n",
    "        else:\n",
    "            info = str(info)\n",
    "        row[data['name']] = info\n",
    "    return row\n",
    "\n",
    "# def read_nat_data(file):\n",
    "#     with open(file) as r:\n",
    "#         for idx, l in enumerate(r):            \n",
    "#             data = read_row_to_table(l, column_reading)\n",
    "#             data['idx'] = idx            \n",
    "#             yield data\n",
    "\n",
    "\n",
    "# a = read_nat_data('Nat2018PublicUS.c20190509.r20190717.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a2 = pd.read_fwf(\n",
    "#     'Nat2018PublicUS.c20190509.r20190717.txt', \n",
    "#     sep='', header=None, chunksize=10000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file_as_df = []\n",
    "# for idx, d in enumerate(a):\n",
    "#     file_as_df.append(d)\n",
    "#     if idx % 100000 == 0:\n",
    "#         print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column_reading = column_reading.sort_values(by=['start'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_int(x):\n",
    "    if not isinstance(x, int) and not isinstance(x, float):\n",
    "        x = int(x) if not x.strip() else np.nan\n",
    "    return x\n",
    "\n",
    "def check_double(x):\n",
    "    if isinstance(x, int):\n",
    "        x = float(x)\n",
    "    elif not isinstance(x, float):\n",
    "        x = float(x) if not x.strip() else np.nan\n",
    "    return x\n",
    "\n",
    "def read_data(file, columns, col_widths, col_df, chunk=1000000):\n",
    "    desired_col = col_df['name'].values\n",
    "    a2 = pd.read_fwf(\n",
    "        file, sep='', \n",
    "        header=None, chunksize=chunk, widths=col_widths\n",
    "    )\n",
    "    groups = col_df.groupby(by=['dtype'])\n",
    "    \n",
    "    for df in a2:\n",
    "        df.columns = columns\n",
    "        \n",
    "        for d, grp in groups:\n",
    "            if d == 'int' or d == 'byte':\n",
    "                df[grp['name'].values] = df[grp['name'].values].applymap(check_int)\n",
    "            elif d == 'double':\n",
    "                df[grp['name'].values] = df[grp['name'].values].applymap(check_double)\n",
    "        \n",
    "        yield df[desired_col]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [f for f in os.listdir('/mnt/nas/natality/') if os.path.isdir('/mnt/nas/natality/' + f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_schema_from_year(year):\n",
    "    if not os.path.isdir('/mnt/nas/natality/' + str(year)):\n",
    "        return None\n",
    "    for f in os.listdir('/mnt/nas/natality/' + str(year)):\n",
    "        if f.endswith('.dct'):\n",
    "            column_df, columns, column_widths = read_dct_file(\n",
    "                os.path.join('/mnt/nas/natality/', str(year), f)\n",
    "            )\n",
    "            return column_df, columns, column_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = {}\n",
    "for i in range(1990, 2020):\n",
    "    c = get_schema_from_year(i)\n",
    "    if c:\n",
    "        c = c[0].set_index('name')['desc']\n",
    "        schemas[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "schema_columns_shared_across_years = pd.concat(schemas, axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_col = schema_columns_shared_across_years.shape[1]\n",
    "cols_shared = ((~schema_columns_shared_across_years.isnull()).sum(axis=1)/total_col).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_mid = schema_columns_shared_across_years[list(range(2014, 2019))].dropna(how='all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plotly.offline import iplot, init_notebook_mode\n",
    "# from plotly import graph_objs as go\n",
    "# init_notebook_mode()\n",
    "\n",
    "# iplot([\n",
    "#     go.Heatmap(\n",
    "#         z=(~decade_mid.isnull()).applymap(lambda x: int(x)).values,\n",
    "#         x=decade_mid.columns,\n",
    "#         y=decade_mid.index\n",
    "#     )\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_columns_shared_across_years.to_csv('/mnt/nas/natality/natality_schema_table.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_from_year(year, chunks=10000):\n",
    "    column_df, columns, column_widths = get_schema_from_year(year)\n",
    "    files_in_folder = os.listdir(os.path.join('/mnt/nas/natality', str(year)))\n",
    "    file_with_nat_data = [f for f in files_in_folder if f.endswith('.txt') and f.startswith('Nat')]\n",
    "    assert len(file_with_nat_data) == 1, 'Failure finding Nat data for ' + str(year)\n",
    "    a = read_data(\n",
    "        os.path.join('/mnt/nas/natality', str(year), file_with_nat_data[0]),\n",
    "        columns, column_widths, column_df, chunk=chunks\n",
    "    )\n",
    "    \n",
    "    dfs = []\n",
    "    total=0\n",
    "    if not os.path.isdir('/mnt/nas/natality/processed'):\n",
    "        os.mkdir('/mnt/nas/natality/processed')\n",
    "    out_path = os.path.join('/mnt/nas/natality/processed', 'Nat_{0}_processed.txt'.format(year))\n",
    "    for i, g in enumerate(a):    \n",
    "        # dfs.append(g)        \n",
    "        total += g.shape[0]\n",
    "        print(i, 'processed', total)\n",
    "        if i == 0:\n",
    "            g.to_csv(out_path, header=True, sep='\\t', mode='w')\n",
    "        else:\n",
    "            g.to_csv(out_path, header=False, sep='\\t', mode='a')\n",
    "    # return pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 processed 10000\n",
      "1 processed 20000\n",
      "2 processed 30000\n",
      "3 processed 40000\n",
      "4 processed 50000\n",
      "5 processed 60000\n",
      "6 processed 70000\n",
      "7 processed 80000\n",
      "8 processed 90000\n",
      "9 processed 100000\n",
      "10 processed 110000\n",
      "11 processed 120000\n",
      "12 processed 130000\n",
      "13 processed 140000\n",
      "14 processed 150000\n",
      "15 processed 160000\n",
      "16 processed 170000\n",
      "17 processed 180000\n",
      "18 processed 190000\n",
      "19 processed 200000\n",
      "20 processed 210000\n",
      "21 processed 220000\n",
      "22 processed 230000\n",
      "23 processed 240000\n",
      "24 processed 250000\n",
      "25 processed 260000\n",
      "26 processed 270000\n",
      "27 processed 280000\n",
      "28 processed 290000\n",
      "29 processed 300000\n",
      "30 processed 310000\n",
      "31 processed 320000\n",
      "32 processed 330000\n",
      "33 processed 340000\n",
      "34 processed 350000\n",
      "35 processed 360000\n",
      "36 processed 370000\n",
      "37 processed 380000\n",
      "38 processed 390000\n",
      "39 processed 400000\n",
      "40 processed 410000\n",
      "41 processed 420000\n",
      "42 processed 430000\n",
      "43 processed 440000\n",
      "44 processed 450000\n",
      "45 processed 460000\n",
      "46 processed 470000\n",
      "47 processed 480000\n",
      "48 processed 490000\n",
      "49 processed 500000\n",
      "50 processed 510000\n",
      "51 processed 520000\n",
      "52 processed 530000\n",
      "53 processed 540000\n",
      "54 processed 550000\n",
      "55 processed 560000\n",
      "56 processed 570000\n",
      "57 processed 580000\n",
      "58 processed 590000\n",
      "59 processed 600000\n",
      "60 processed 610000\n",
      "61 processed 620000\n",
      "62 processed 630000\n",
      "63 processed 640000\n",
      "64 processed 650000\n",
      "65 processed 660000\n",
      "66 processed 670000\n",
      "67 processed 680000\n",
      "68 processed 690000\n",
      "69 processed 700000\n",
      "70 processed 710000\n",
      "71 processed 720000\n",
      "72 processed 730000\n",
      "73 processed 740000\n",
      "74 processed 750000\n",
      "75 processed 760000\n",
      "76 processed 770000\n",
      "77 processed 780000\n",
      "78 processed 790000\n",
      "79 processed 800000\n",
      "80 processed 810000\n",
      "81 processed 820000\n",
      "82 processed 830000\n",
      "83 processed 840000\n",
      "84 processed 850000\n",
      "85 processed 860000\n",
      "86 processed 870000\n",
      "87 processed 880000\n",
      "88 processed 890000\n",
      "89 processed 900000\n",
      "90 processed 910000\n",
      "91 processed 920000\n",
      "92 processed 930000\n",
      "93 processed 940000\n",
      "94 processed 950000\n",
      "95 processed 960000\n",
      "96 processed 970000\n",
      "97 processed 980000\n",
      "98 processed 990000\n",
      "99 processed 1000000\n",
      "100 processed 1010000\n",
      "101 processed 1020000\n",
      "102 processed 1030000\n",
      "103 processed 1040000\n",
      "104 processed 1050000\n",
      "105 processed 1060000\n",
      "106 processed 1070000\n",
      "107 processed 1080000\n",
      "108 processed 1090000\n",
      "109 processed 1100000\n",
      "110 processed 1110000\n",
      "111 processed 1120000\n",
      "112 processed 1130000\n",
      "113 processed 1140000\n",
      "114 processed 1150000\n",
      "115 processed 1160000\n",
      "116 processed 1170000\n",
      "117 processed 1180000\n",
      "118 processed 1190000\n",
      "119 processed 1200000\n",
      "120 processed 1210000\n",
      "121 processed 1220000\n",
      "122 processed 1230000\n",
      "123 processed 1240000\n",
      "124 processed 1250000\n",
      "125 processed 1260000\n",
      "126 processed 1270000\n",
      "127 processed 1280000\n",
      "128 processed 1290000\n",
      "129 processed 1300000\n",
      "130 processed 1310000\n",
      "131 processed 1320000\n",
      "132 processed 1330000\n",
      "133 processed 1340000\n",
      "134 processed 1350000\n",
      "135 processed 1360000\n",
      "136 processed 1370000\n",
      "137 processed 1380000\n",
      "138 processed 1390000\n",
      "139 processed 1400000\n",
      "140 processed 1410000\n",
      "141 processed 1420000\n",
      "142 processed 1430000\n",
      "143 processed 1440000\n",
      "144 processed 1450000\n",
      "145 processed 1460000\n",
      "146 processed 1470000\n",
      "147 processed 1480000\n",
      "148 processed 1490000\n",
      "149 processed 1500000\n",
      "150 processed 1510000\n",
      "151 processed 1520000\n",
      "152 processed 1530000\n",
      "153 processed 1540000\n",
      "154 processed 1550000\n",
      "155 processed 1560000\n",
      "156 processed 1570000\n",
      "157 processed 1580000\n",
      "158 processed 1590000\n",
      "159 processed 1600000\n",
      "160 processed 1610000\n",
      "161 processed 1620000\n",
      "162 processed 1630000\n",
      "163 processed 1640000\n",
      "164 processed 1650000\n",
      "165 processed 1660000\n",
      "166 processed 1670000\n",
      "167 processed 1680000\n",
      "168 processed 1690000\n",
      "169 processed 1700000\n",
      "170 processed 1710000\n",
      "171 processed 1720000\n",
      "172 processed 1730000\n",
      "173 processed 1740000\n",
      "174 processed 1750000\n",
      "175 processed 1760000\n",
      "176 processed 1770000\n",
      "177 processed 1780000\n",
      "178 processed 1790000\n",
      "179 processed 1800000\n",
      "180 processed 1810000\n",
      "181 processed 1820000\n",
      "182 processed 1830000\n",
      "183 processed 1840000\n",
      "184 processed 1850000\n",
      "185 processed 1860000\n",
      "186 processed 1870000\n",
      "187 processed 1880000\n",
      "188 processed 1890000\n",
      "189 processed 1900000\n",
      "190 processed 1910000\n",
      "191 processed 1920000\n",
      "192 processed 1930000\n",
      "193 processed 1940000\n",
      "194 processed 1950000\n",
      "195 processed 1960000\n",
      "196 processed 1970000\n",
      "197 processed 1980000\n",
      "198 processed 1990000\n",
      "199 processed 2000000\n",
      "200 processed 2010000\n",
      "201 processed 2020000\n",
      "202 processed 2030000\n",
      "203 processed 2040000\n",
      "204 processed 2050000\n",
      "205 processed 2060000\n",
      "206 processed 2070000\n",
      "207 processed 2080000\n",
      "208 processed 2090000\n",
      "209 processed 2100000\n",
      "210 processed 2110000\n",
      "211 processed 2120000\n",
      "212 processed 2130000\n",
      "213 processed 2140000\n",
      "214 processed 2150000\n",
      "215 processed 2160000\n",
      "216 processed 2170000\n",
      "217 processed 2180000\n",
      "218 processed 2190000\n",
      "219 processed 2200000\n",
      "220 processed 2210000\n",
      "221 processed 2220000\n",
      "222 processed 2230000\n",
      "223 processed 2240000\n",
      "224 processed 2250000\n",
      "225 processed 2260000\n",
      "226 processed 2270000\n",
      "227 processed 2280000\n",
      "228 processed 2290000\n",
      "229 processed 2300000\n",
      "230 processed 2310000\n",
      "231 processed 2320000\n",
      "232 processed 2330000\n",
      "233 processed 2340000\n",
      "234 processed 2350000\n",
      "235 processed 2360000\n",
      "236 processed 2370000\n",
      "237 processed 2380000\n",
      "238 processed 2390000\n",
      "239 processed 2400000\n",
      "240 processed 2410000\n",
      "241 processed 2420000\n",
      "242 processed 2430000\n",
      "243 processed 2440000\n",
      "244 processed 2450000\n",
      "245 processed 2460000\n",
      "246 processed 2470000\n",
      "247 processed 2480000\n",
      "248 processed 2490000\n",
      "249 processed 2500000\n",
      "250 processed 2510000\n",
      "251 processed 2520000\n",
      "252 processed 2530000\n",
      "253 processed 2540000\n",
      "254 processed 2550000\n",
      "255 processed 2560000\n",
      "256 processed 2570000\n",
      "257 processed 2580000\n",
      "258 processed 2590000\n",
      "259 processed 2600000\n",
      "260 processed 2610000\n",
      "261 processed 2620000\n",
      "262 processed 2630000\n",
      "263 processed 2640000\n",
      "264 processed 2650000\n",
      "265 processed 2660000\n",
      "266 processed 2670000\n",
      "267 processed 2680000\n",
      "268 processed 2690000\n",
      "269 processed 2700000\n",
      "270 processed 2710000\n",
      "271 processed 2720000\n",
      "272 processed 2730000\n",
      "273 processed 2740000\n",
      "274 processed 2750000\n",
      "275 processed 2760000\n",
      "276 processed 2770000\n",
      "277 processed 2780000\n",
      "278 processed 2790000\n",
      "279 processed 2800000\n",
      "280 processed 2810000\n",
      "281 processed 2820000\n",
      "282 processed 2830000\n",
      "283 processed 2840000\n",
      "284 processed 2850000\n",
      "285 processed 2860000\n",
      "286 processed 2870000\n",
      "287 processed 2880000\n",
      "288 processed 2890000\n",
      "289 processed 2900000\n",
      "290 processed 2910000\n",
      "291 processed 2920000\n",
      "292 processed 2930000\n",
      "293 processed 2940000\n",
      "294 processed 2950000\n",
      "295 processed 2960000\n",
      "296 processed 2970000\n",
      "297 processed 2980000\n",
      "298 processed 2990000\n",
      "299 processed 3000000\n",
      "300 processed 3010000\n",
      "301 processed 3020000\n",
      "302 processed 3030000\n",
      "303 processed 3040000\n",
      "304 processed 3050000\n",
      "305 processed 3060000\n",
      "306 processed 3070000\n",
      "307 processed 3080000\n",
      "308 processed 3090000\n",
      "309 processed 3100000\n",
      "310 processed 3110000\n",
      "311 processed 3120000\n",
      "312 processed 3130000\n",
      "313 processed 3140000\n",
      "314 processed 3150000\n",
      "315 processed 3160000\n",
      "316 processed 3170000\n",
      "317 processed 3180000\n",
      "318 processed 3190000\n",
      "319 processed 3200000\n",
      "320 processed 3210000\n",
      "321 processed 3220000\n",
      "322 processed 3230000\n",
      "323 processed 3240000\n",
      "324 processed 3250000\n",
      "325 processed 3260000\n",
      "326 processed 3270000\n",
      "327 processed 3280000\n",
      "328 processed 3290000\n",
      "329 processed 3300000\n",
      "330 processed 3310000\n",
      "331 processed 3320000\n",
      "332 processed 3330000\n",
      "333 processed 3340000\n",
      "334 processed 3350000\n",
      "335 processed 3360000\n",
      "336 processed 3370000\n",
      "337 processed 3380000\n",
      "338 processed 3390000\n",
      "339 processed 3400000\n",
      "340 processed 3410000\n",
      "341 processed 3420000\n",
      "342 processed 3430000\n",
      "343 processed 3440000\n",
      "344 processed 3450000\n",
      "345 processed 3460000\n",
      "346 processed 3470000\n",
      "347 processed 3480000\n",
      "348 processed 3490000\n",
      "349 processed 3500000\n",
      "350 processed 3510000\n",
      "351 processed 3520000\n",
      "352 processed 3530000\n",
      "353 processed 3540000\n",
      "354 processed 3550000\n",
      "355 processed 3560000\n",
      "356 processed 3570000\n",
      "357 processed 3580000\n",
      "358 processed 3590000\n",
      "359 processed 3600000\n"
     ]
    }
   ],
   "source": [
    "process_data_from_year(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015 = process_data_from_year(2015)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
